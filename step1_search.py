# YOUTUBE_API_KEY = "AIzaSyBE1Q3uPePfIiaImcD8EcVD3jo4dcqTp-I"

"""
YouTubeè§†é¢‘æœç´¢ - ç¬¬ä¸€æ­¥ï¼šè·å–åˆ—è¡¨å¹¶å¯¼å‡ºCSV
"""

import os
import csv
import time
from datetime import datetime
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

# ============================================================================
# é…ç½®éƒ¨åˆ†
# ============================================================================

# ğŸ”‘ é‡è¦ï¼šè¯·ç”¨ä½ çš„æ–°API Keyæ›¿æ¢è¿™é‡Œï¼ˆå·²æ’¤é”€æ—§çš„ï¼‰
YOUTUBE_API_KEY = "AIzaSyBE1Q3uPePfIiaImcD8EcVD3jo4dcqTp-I"

# æœç´¢å…³é”®è¯ - ä½¿ç”¨å¸ƒå°”è¿ç®—ç¬¦ä¼˜åŒ–æœç´¢
SEARCH_QUERY = 'inflation ("What is" OR "Explained" OR "what you need to know" OR "deep dive")'

# è¿‡æ»¤æ¡ä»¶
LANGUAGE = 'en'  # è‹±æ–‡
DATE_AFTER = '2021-06-01T00:00:00Z'  # 2021å¹´6æœˆå¼€å§‹
DATE_BEFORE = '2024-02-29T23:59:59Z'  # 2024å¹´2æœˆç»“æŸ

# è¾“å‡ºç›®å½•å’Œæ–‡ä»¶å
OUTPUT_DIR = "youtube_results"
VIDEOS_CSV = os.path.join(OUTPUT_DIR, "videos.csv")
CHANNELS_CSV = os.path.join(OUTPUT_DIR, "channels.csv")

# æœ€å¤šè·å–çš„ç»“æœæ•°
MAX_RESULTS = 400  # å¯ä»¥è®¾ç½®æ›´å¤§çš„å€¼ï¼Œå› ä¸ºåªæœç´¢ä¸€æ¬¡


# ============================================================================
# ä¸»ç¨‹åº
# ============================================================================

def search_videos(youtube, query, max_results=50, language='en', date_after=None, date_before=None):
    """æœç´¢è§†é¢‘å¹¶è¿”å›video IDs"""
    print(f"\nğŸ” æœç´¢: '{query}'")
    print(f"   è¯­è¨€: {language}")
    if date_after:
        print(f"   æ—¶é—´èŒƒå›´: {date_after[:10]} è‡³ {date_before[:10] if date_before else 'ç°åœ¨'}")

    video_ids = []
    next_page_token = None

    while len(video_ids) < max_results:
        try:
            search_params = {
                'q': query,
                'type': 'video',
                'part': 'id',
                'maxResults': min(50, max_results - len(video_ids)),
                'pageToken': next_page_token,
                'relevanceLanguage': language,
                'videoCaption': 'any'
            }

            # æ·»åŠ æ—¶é—´è¿‡æ»¤
            if date_after:
                search_params['publishedAfter'] = date_after
            if date_before:
                search_params['publishedBefore'] = date_before

            search_response = youtube.search().list(**search_params).execute()

            for item in search_response.get('items', []):
                video_ids.append(item['id']['videoId'])

            next_page_token = search_response.get('nextPageToken')

            if not next_page_token:
                break

            time.sleep(0.5)

        except HttpError as e:
            print(f"âŒ APIé”™è¯¯: {e}")
            break

    print(f"âœ… æ‰¾åˆ° {len(video_ids)} ä¸ªè§†é¢‘")
    return video_ids


def get_video_details(youtube, video_ids):
    """è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯"""
    print(f"\nğŸ“Š è·å– {len(video_ids)} ä¸ªè§†é¢‘çš„è¯¦ç»†ä¿¡æ¯...")

    videos_data = []

    # YouTube API ä¸€æ¬¡æœ€å¤šæŸ¥è¯¢50ä¸ªè§†é¢‘
    for i in range(0, len(video_ids), 50):
        batch = video_ids[i:i + 50]

        try:
            response = youtube.videos().list(
                part='id,snippet,contentDetails,statistics,recordingDetails',
                id=','.join(batch)
            ).execute()

            for item in response.get('items', []):
                video_data = {
                    'video_id': item['id'],
                    'channel_id': item['snippet']['channelId'],
                    'channel_title': item['snippet']['channelTitle'],
                    'title': item['snippet']['title'],
                    'description': item['snippet']['description'][:500],  # é™åˆ¶é•¿åº¦
                    'published_at': item['snippet']['publishedAt'],
                    'recording_date': item.get('recordingDetails', {}).get('recordingDate', ''),
                    'duration': item['contentDetails']['duration'],
                    'definition': item['contentDetails']['definition'],
                    'caption': item['contentDetails']['caption'],
                    'tags': '|'.join(item['snippet'].get('tags', [])),
                    'default_language': item['snippet'].get('defaultLanguage', ''),
                    'default_audio_language': item['snippet'].get('defaultAudioLanguage', ''),
                    'category_id': item['snippet'].get('categoryId', ''),
                    'view_count': item['statistics'].get('viewCount', 0),
                    'like_count': item['statistics'].get('likeCount', 0),
                    'comment_count': item['statistics'].get('commentCount', 0),
                    'video_url': f"https://www.youtube.com/watch?v={item['id']}"
                }

                videos_data.append(video_data)

            print(f"  è¿›åº¦: {min(i + 50, len(video_ids))}/{len(video_ids)}")
            time.sleep(0.5)

        except HttpError as e:
            print(f"âŒ è·å–è§†é¢‘è¯¦æƒ…é”™è¯¯: {e}")

    print(f"âœ… æˆåŠŸè·å– {len(videos_data)} ä¸ªè§†é¢‘çš„è¯¦ç»†ä¿¡æ¯")
    return videos_data


def get_channel_details(youtube, channel_ids):
    """è·å–é¢‘é“è¯¦ç»†ä¿¡æ¯"""
    print(f"\nğŸ“º è·å–é¢‘é“ä¿¡æ¯...")

    channels_data = []
    unique_channel_ids = list(set(channel_ids))

    for i in range(0, len(unique_channel_ids), 50):
        batch = unique_channel_ids[i:i + 50]

        try:
            response = youtube.channels().list(
                part='id,snippet,contentDetails,statistics,brandingSettings',
                id=','.join(batch)
            ).execute()

            for item in response.get('items', []):
                channel_data = {
                    'channel_id': item['id'],
                    'channel_title': item['snippet']['title'],
                    'custom_url': item['snippet'].get('customUrl', ''),
                    'description': item['snippet']['description'][:500],  # é™åˆ¶é•¿åº¦
                    'country': item['snippet'].get('country', ''),
                    'published_at': item['snippet']['publishedAt'],
                    'subscriber_count': item['statistics'].get('subscriberCount', 0),
                    'video_count': item['statistics'].get('videoCount', 0),
                    'view_count': item['statistics'].get('viewCount', 0),
                    'keywords': item.get('brandingSettings', {}).get('channel', {}).get('keywords', ''),
                    'channel_url': f"https://www.youtube.com/channel/{item['id']}"
                }

                channels_data.append(channel_data)

            print(f"  è¿›åº¦: {min(i + 50, len(unique_channel_ids))}/{len(unique_channel_ids)}")
            time.sleep(0.5)

        except HttpError as e:
            print(f"âŒ è·å–é¢‘é“è¯¦æƒ…é”™è¯¯: {e}")

    print(f"âœ… æˆåŠŸè·å– {len(channels_data)} ä¸ªé¢‘é“çš„è¯¦ç»†ä¿¡æ¯")
    return channels_data


def save_to_csv(data, filename, fieldnames):
    """ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶"""
    os.makedirs(os.path.dirname(filename), exist_ok=True)

    with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(data)

    print(f"ğŸ’¾ å·²ä¿å­˜åˆ°: {filename}")


def main():
    print("=" * 70)
    print("YouTube è§†é¢‘æœç´¢ - ç¬¬ä¸€æ­¥ï¼šè·å–åˆ—è¡¨å¹¶å¯¼å‡ºCSV")
    print("=" * 70)
    print(f"\nğŸ“‹ æœç´¢é…ç½®:")
    print(f"   å…³é”®è¯: {SEARCH_QUERY}")
    print(f"   è¯­è¨€: English ({LANGUAGE})")
    print(f"   æ—¶é—´èŒƒå›´: {DATE_AFTER[:10]} è‡³ {DATE_BEFORE[:10]}")
    print(f"   æœ€å¤§ç»“æœæ•°: {MAX_RESULTS}")

    # æ£€æŸ¥API Key
    if YOUTUBE_API_KEY == "YOUR_NEW_API_KEY_HERE":
        print("\nâŒ é”™è¯¯: è¯·å…ˆæ›¿æ¢ä»£ç ä¸­çš„ YOUTUBE_API_KEY")
        print("è¯·ç”¨ä½ çš„æ–°API Keyæ›¿æ¢ç¬¬16è¡Œçš„ YOUR_NEW_API_KEY_HERE")
        return

    # åˆå§‹åŒ–YouTube APIå®¢æˆ·ç«¯
    try:
        youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)
        print("âœ… YouTube API åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ API åˆå§‹åŒ–å¤±è´¥: {e}")
        return

    # ========== ç¬¬ä¸€æ­¥ï¼šæœç´¢è§†é¢‘ ==========
    # ä½¿ç”¨å•æ¬¡å¸ƒå°”æœç´¢ï¼ˆæ¨èï¼‰
    print(f"\nğŸ” ä½¿ç”¨æœç´¢æŸ¥è¯¢: {SEARCH_QUERY}")
    video_ids = search_videos(
        youtube,
        SEARCH_QUERY,
        MAX_RESULTS,
        language=LANGUAGE,
        date_after=DATE_AFTER,
        date_before=DATE_BEFORE
    )

    # å¦‚æœæƒ³ä½¿ç”¨å¤šæ¬¡æœç´¢ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Šå¹¶æ³¨é‡Šæ‰ä¸Šé¢çš„ä»£ç 
    # all_video_ids = []
    # for query in SEARCH_QUERIES:
    #     video_ids = search_videos(youtube, query, 50, LANGUAGE, DATE_AFTER, DATE_BEFORE)
    #     all_video_ids.extend(video_ids)
    # video_ids = list(set(all_video_ids))  # å»é‡

    print(f"\nğŸ“‹ æ€»å…±æ‰¾åˆ° {len(video_ids)} ä¸ªè§†é¢‘")

    # ========== ç¬¬äºŒæ­¥ï¼šè·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯ ==========
    videos_data = get_video_details(youtube, video_ids)

    # ========== ç¬¬ä¸‰æ­¥ï¼šè·å–é¢‘é“ä¿¡æ¯ ==========
    channel_ids = [video['channel_id'] for video in videos_data]
    channels_data = get_channel_details(youtube, channel_ids)

    # ========== ç¬¬å››æ­¥ï¼šä¿å­˜ä¸ºCSV ==========
    print("\nğŸ’¾ ä¿å­˜æ•°æ®åˆ°CSV...")

    # ä¿å­˜è§†é¢‘æ•°æ®
    video_fields = [
        'video_id', 'channel_id', 'channel_title', 'title', 'description',
        'published_at', 'recording_date', 'duration', 'definition', 'caption',
        'tags', 'default_language', 'default_audio_language', 'category_id',
        'view_count', 'like_count', 'comment_count', 'video_url'
    ]
    save_to_csv(videos_data, VIDEOS_CSV, video_fields)

    # ä¿å­˜é¢‘é“æ•°æ®
    channel_fields = [
        'channel_id', 'channel_title', 'custom_url', 'description', 'country',
        'published_at', 'subscriber_count', 'video_count', 'view_count',
        'keywords', 'channel_url'
    ]
    save_to_csv(channels_data, CHANNELS_CSV, channel_fields)

    # ========== å®Œæˆ ==========
    print("\n" + "=" * 70)
    print("âœ… ç¬¬ä¸€æ­¥å®Œæˆ!")
    print("=" * 70)
    print(f"\nğŸ“Š ç»Ÿè®¡:")
    print(f"  - è§†é¢‘æ•°é‡: {len(videos_data)}")
    print(f"  - é¢‘é“æ•°é‡: {len(channels_data)}")
    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"  - è§†é¢‘åˆ—è¡¨: {VIDEOS_CSV}")
    print(f"  - é¢‘é“åˆ—è¡¨: {CHANNELS_CSV}")
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥: ä½¿ç”¨è¿™äº›video_idè¿›è¡Œè§†é¢‘ä¸‹è½½")


if __name__ == "__main__":
    main()