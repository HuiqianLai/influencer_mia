"""
YouTubeè§†é¢‘ä¸‹è½½ - ç¬¬äºŒæ­¥æµ‹è¯•ç‰ˆï¼šä½¿ç”¨yt-dlpè·å–æ‰€æœ‰ç»´åº¦ä¿¡æ¯
æµ‹è¯•å‰10ä¸ªè§†é¢‘
"""

import os
import csv
import json
import time
from datetime import datetime
import yt_dlp

# ============================================================================
# é…ç½®éƒ¨åˆ†
# ============================================================================

# è¾“å…¥æ–‡ä»¶ï¼ˆç¬¬ä¸€æ­¥ç”Ÿæˆçš„CSVï¼‰
INPUT_CSV = "youtube_results/videos.csv"

# è¾“å‡ºç›®å½•
OUTPUT_DIR = "youtube_downloads_test"
METADATA_DIR = os.path.join(OUTPUT_DIR, "metadata")
TRANSCRIPTS_DIR = os.path.join(OUTPUT_DIR, "transcripts")
CHANNELS_DIR = os.path.join(OUTPUT_DIR, "channels")
VIDEOS_DIR = os.path.join(OUTPUT_DIR, "videos")  # è§†é¢‘æ–‡ä»¶ç›®å½•

# æµ‹è¯•ï¼šåªä¸‹è½½å‰Nä¸ªè§†é¢‘
TEST_LIMIT = 150

# ä¸‹è½½è§†é¢‘è®¾ç½®
DOWNLOAD_VIDEO = True  # æ˜¯å¦ä¸‹è½½è§†é¢‘æ–‡ä»¶
VIDEO_QUALITY = 'best'  # è§†é¢‘è´¨é‡ï¼š'best' (æœ€é«˜è´¨é‡) æˆ– '1080p', '720p' ç­‰

# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================

def read_video_ids_from_csv(csv_file, limit=None):
    """ä»CSVæ–‡ä»¶è¯»å–video_idåˆ—è¡¨"""
    video_ids = []

    if not os.path.exists(csv_file):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {csv_file}")
        print("è¯·å…ˆè¿è¡Œç¬¬ä¸€æ­¥ä»£ç ç”Ÿæˆvideos.csv")
        return []

    with open(csv_file, 'r', encoding='utf-8-sig') as f:
        reader = csv.DictReader(f)
        for row in reader:
            video_ids.append(row['video_id'])
            if limit and len(video_ids) >= limit:
                break

    return video_ids


def clean_info_for_json(info):
    """
    æ¸…ç† yt-dlp è¿”å›çš„ info å¯¹è±¡ï¼Œç§»é™¤ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
    èƒ½åºåˆ—åŒ–çš„éƒ½ä¿ç•™ï¼Œä¸èƒ½åºåˆ—åŒ–çš„å°±è·³è¿‡
    """
    if info is None:
        return None

    # å¦‚æœä¸æ˜¯å­—å…¸ã€åˆ—è¡¨ç­‰å¤æ‚ç±»å‹ï¼Œç›´æ¥æµ‹è¯•èƒ½å¦åºåˆ—åŒ–
    if not isinstance(info, (dict, list, tuple)):
        try:
            json.dumps(info)
            return info
        except (TypeError, ValueError):
            return None  # ä¸èƒ½åºåˆ—åŒ–å°±è¿”å› None

    # å¤„ç†å­—å…¸
    if isinstance(info, dict):
        cleaned = {}
        for key, value in info.items():
            try:
                # é€’å½’æ¸…ç†å€¼
                cleaned_value = clean_info_for_json(value)

                # å¦‚æœæ¸…ç†åçš„å€¼ä¸æ˜¯ Noneï¼Œå°±ä¿å­˜
                if cleaned_value is not None:
                    cleaned[key] = cleaned_value
                # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœåŸå€¼å°±æ˜¯ Noneï¼Œä¹Ÿè¦ä¿ç•™
                elif value is None:
                    cleaned[key] = None

            except Exception as e:
                # ä»»ä½•å¼‚å¸¸éƒ½è·³è¿‡è¿™ä¸ªå­—æ®µ
                print(f"    âš ï¸  è·³è¿‡å­—æ®µ '{key}': {type(value).__name__}")
                continue

        return cleaned

    # å¤„ç†åˆ—è¡¨æˆ–å…ƒç»„
    if isinstance(info, (list, tuple)):
        cleaned_list = []
        for item in info:
            try:
                cleaned_item = clean_info_for_json(item)
                if cleaned_item is not None or item is None:
                    cleaned_list.append(cleaned_item)
            except Exception:
                # è·³è¿‡ä¸èƒ½åºåˆ—åŒ–çš„åˆ—è¡¨é¡¹
                continue

        return cleaned_list if isinstance(info, list) else tuple(cleaned_list)

    # å…¶ä»–ç±»å‹å°è¯•ç›´æ¥åºåˆ—åŒ–
    try:
        json.dumps(info)
        return info
    except (TypeError, ValueError):
        return None


def extract_channel_info(info):
    """ä»yt-dlpè¿”å›çš„infoä¸­æå–é¢‘é“ä¿¡æ¯"""
    channel_data = {
        # IDs & metadata
        'channel_id': info.get('channel_id'),
        'custom_url': info.get('channel_url', '').replace('https://www.youtube.com/channel/', '').replace('https://www.youtube.com/', ''),
        'channel_handle': info.get('uploader_id'),  # @handle
        'title': info.get('channel'),
        'uploader': info.get('uploader'),

        # Descriptionéœ€è¦ä»å®Œæ•´é¢‘é“é¡µé¢è·å–ï¼Œè¿™é‡Œå…ˆç•™ç©º
        'description': '',
        'country': '',

        # Ownership/affiliation signals
        'channel_follower_count': info.get('channel_follower_count'),

        # Links - yt-dlpå¯èƒ½ä¸ç›´æ¥æä¾›ï¼Œéœ€è¦é¢å¤–æŠ“å–
        'external_links': [],
        'business_email': '',
    }

    return channel_data


def extract_video_info(info):
    """ä»yt-dlpè¿”å›çš„infoä¸­æå–è§†é¢‘ä¿¡æ¯"""
    video_data = {
        # IDs & timestamps
        'video_id': info.get('id'),
        'channel_id': info.get('channel_id'),
        'published_at': info.get('upload_date'),  # YYYYMMDDæ ¼å¼
        'timestamp': info.get('timestamp'),  # Unix timestamp
        'release_timestamp': info.get('release_timestamp'),

        # Textual metadata
        'title': info.get('title'),
        'description': info.get('description'),
        'tags': info.get('tags', []),
        'categories': info.get('categories', []),
        'default_language': info.get('language'),

        # Duration/format
        'duration': info.get('duration'),  # ç§’æ•°
        'duration_string': info.get('duration_string'),
        'definition': 'hd' if info.get('height', 0) >= 720 else 'sd',
        'resolution': info.get('resolution'),
        'width': info.get('width'),
        'height': info.get('height'),
        'fps': info.get('fps'),
        'vcodec': info.get('vcodec'),
        'acodec': info.get('acodec'),
        'filesize': info.get('filesize'),  # æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        'filesize_approx': info.get('filesize_approx'),

        # Captions
        'has_subtitles': bool(info.get('subtitles')),
        'has_automatic_captions': bool(info.get('automatic_captions')),
        'available_subtitles': list(info.get('subtitles', {}).keys()),
        'available_auto_captions': list(info.get('automatic_captions', {}).keys()),

        # Content rating
        'age_limit': info.get('age_limit'),
        'is_live': info.get('is_live'),
        'was_live': info.get('was_live'),

        # Statistics
        'view_count': info.get('view_count'),
        'like_count': info.get('like_count'),
        'comment_count': info.get('comment_count'),

        # Additional
        'thumbnail': info.get('thumbnail'),
        'webpage_url': info.get('webpage_url'),
        'channel_url': info.get('channel_url'),
    }

    return video_data


def extract_transcript_info(subtitles_data, video_id):
    """æå–å­—å¹•ä¿¡æ¯ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰"""
    transcripts = []

    if not subtitles_data:
        return transcripts

    # æ£€æŸ¥ä¸¤ä¸ªå¯èƒ½çš„ç›®å½•
    search_dirs = [TRANSCRIPTS_DIR, VIDEOS_DIR]
    subtitle_files = []

    for search_dir in search_dirs:
        video_dir = os.path.join(search_dir, video_id)
        if os.path.exists(video_dir):
            subtitle_files = [
                os.path.join(video_dir, f)
                for f in os.listdir(video_dir)
                if f.startswith(video_id) and f.endswith('.json3')
            ]
            if subtitle_files:
                break

    for subtitle_file in subtitle_files:
        try:
            with open(subtitle_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

                # JSON3æ ¼å¼åŒ…å«å®Œæ•´çš„æ—¶é—´æˆ³ä¿¡æ¯
                if 'events' in data:
                    segments = []
                    for event in data['events']:
                        if 'segs' in event:
                            text = ''.join([seg.get('utf8', '') for seg in event['segs']])
                            segments.append({
                                'start_ms': event.get('tStartMs', 0),
                                'end_ms': event.get('tStartMs', 0) + event.get('dDurationMs', 0),
                                'text': text.strip()
                            })

                    lang = os.path.basename(subtitle_file).split('.')[-2]
                    transcripts.append({
                        'language': lang,
                        'segments': segments
                    })
        except Exception as e:
            print(f"  âš ï¸  è§£æå­—å¹•æ–‡ä»¶å¤±è´¥ {os.path.basename(subtitle_file)}: {e}")

    return transcripts

    return transcripts


def download_video_metadata(video_id, output_dir, download_video=True, video_quality='best'):
    """
    ä½¿ç”¨yt-dlpä¸‹è½½å•ä¸ªè§†é¢‘çš„æ‰€æœ‰å…ƒæ•°æ®å’Œè§†é¢‘æ–‡ä»¶

    Args:
        video_id: è§†é¢‘ID
        output_dir: è¾“å‡ºç›®å½•
        download_video: æ˜¯å¦ä¸‹è½½è§†é¢‘æ–‡ä»¶
        video_quality: è§†é¢‘è´¨é‡ ('best', '1080p', '720p', etc.)
    """
    url = f"https://www.youtube.com/watch?v={video_id}"

    # åˆ›å»ºè§†é¢‘ä¸“å±ç›®å½•
    video_dir = os.path.join(output_dir, video_id)
    os.makedirs(video_dir, exist_ok=True)

    # åŸºç¡€é…ç½®
    ydl_opts = {
        # è¾“å‡ºè·¯å¾„ - åªè®¾ç½® outtmplï¼Œä¸è®¾ç½® paths
        'outtmpl': os.path.join(video_dir, '%(id)s.%(ext)s'),

        # ä¿å­˜å®Œæ•´çš„JSONä¿¡æ¯
        'writeinfojson': True,
        'clean_infojson': False,

        # ä¸‹è½½å­—å¹•ï¼ˆæ‰€æœ‰å¯ç”¨è¯­è¨€ï¼‰
        'writesubtitles': True,
        'writeautomaticsub': True,
        'subtitleslangs': ['en', 'en-US', 'en-GB'],
        'subtitlesformat': 'json3',

        # ä¸‹è½½å…¶ä»–å…ƒæ•°æ®
        'writethumbnail': True,
        'writedescription': True,

        # è·å–å®Œæ•´ä¿¡æ¯
        'extract_flat': False,
        'forcejson': True,

        # è¾“å‡ºæ§åˆ¶
        'quiet': False,
        'no_warnings': False,
    }

    # å¦‚æœä¸‹è½½è§†é¢‘ï¼Œé…ç½®è§†é¢‘æ ¼å¼
    if download_video:
        # æ ¼å¼é€‰æ‹©ï¼šä¼˜å…ˆä¸‹è½½æœ€é«˜è´¨é‡çš„MP4æ ¼å¼
        # bestvideo[ext=mp4]+bestaudio[ext=m4a] = æœ€é«˜è´¨é‡çš„MP4è§†é¢‘+éŸ³é¢‘
        # best[ext=mp4] = å¦‚æœä¸Šé¢çš„æ ¼å¼ä¸å¯ç”¨ï¼Œä¸‹è½½æœ€å¥½çš„MP4
        # best = æœ€åçš„fallbackï¼Œä¸‹è½½ä»»ä½•æ ¼å¼çš„æœ€é«˜è´¨é‡
        format_string = 'bestvideo[ext=mp4][height<=1080]+bestaudio[ext=m4a]/best[ext=mp4][height<=1080]/bestvideo+bestaudio/best'

        if video_quality == '720p':
            format_string = 'bestvideo[ext=mp4][height<=720]+bestaudio[ext=m4a]/best[ext=mp4][height<=720]/best'
        elif video_quality == '480p':
            format_string = 'bestvideo[ext=mp4][height<=480]+bestaudio[ext=m4a]/best[ext=mp4][height<=480]/best'
        elif video_quality == 'best':
            format_string = 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/bestvideo+bestaudio/best'

        ydl_opts.update({
            'format': format_string,
            'merge_output_format': 'mp4',  # åˆå¹¶ä¸ºMP4æ ¼å¼
        })
        print(f"  ğŸ“¹ ä¸‹è½½è§†é¢‘: {video_quality}")
    else:
        ydl_opts['skip_download'] = True
        print(f"  ğŸ“„ ä»…ä¸‹è½½å…ƒæ•°æ®ï¼ˆä¸ä¸‹è½½è§†é¢‘ï¼‰")

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            print(f"  ğŸ“¥ å¤„ç†: {video_id}")
            info = ydl.extract_info(url, download=True)

            return info

    except Exception as e:
        print(f"  âŒ å¤±è´¥: {e}")
        return None


def process_videos(video_ids, download_video=True, video_quality='best'):
    """æ‰¹é‡å¤„ç†è§†é¢‘"""
    print(f"\nğŸš€ å¼€å§‹å¤„ç† {len(video_ids)} ä¸ªè§†é¢‘")
    if download_video:
        print(f"   è§†é¢‘è´¨é‡: {video_quality}")
        print(f"   âš ï¸  ä¸‹è½½è§†é¢‘éœ€è¦è¾ƒé•¿æ—¶é—´å’Œå­˜å‚¨ç©ºé—´")

    os.makedirs(METADATA_DIR, exist_ok=True)
    os.makedirs(TRANSCRIPTS_DIR, exist_ok=True)
    os.makedirs(CHANNELS_DIR, exist_ok=True)
    if download_video:
        os.makedirs(VIDEOS_DIR, exist_ok=True)

    all_videos = []
    all_channels = {}
    all_transcripts = []

    for i, video_id in enumerate(video_ids, 1):
        print(f"\n[{i}/{len(video_ids)}] å¤„ç†è§†é¢‘: {video_id}")

        # ä¸‹è½½å…ƒæ•°æ®å’Œè§†é¢‘
        output_location = VIDEOS_DIR if download_video else TRANSCRIPTS_DIR
        info = download_video_metadata(video_id, output_location, download_video, video_quality)

        if info:
            # æå–è§†é¢‘ä¿¡æ¯
            video_data = extract_video_info(info)
            all_videos.append(video_data)

            # æå–é¢‘é“ä¿¡æ¯
            channel_id = info.get('channel_id')
            if channel_id and channel_id not in all_channels:
                channel_data = extract_channel_info(info)
                all_channels[channel_id] = channel_data

            # æå–å­—å¹•ä¿¡æ¯
            transcript_data = extract_transcript_info(
                info.get('subtitles') or info.get('automatic_captions'),
                video_id
            )

            if transcript_data:
                all_transcripts.append({
                    'video_id': video_id,
                    'transcripts': transcript_data
                })

            # ä¿å­˜å®Œæ•´çš„JSONä¿¡æ¯ï¼ˆæ¸…ç†åï¼‰
            json_path = os.path.join(METADATA_DIR, f"{video_id}_full.json")
            with open(json_path, 'w', encoding='utf-8') as f:
                cleaned_info = clean_info_for_json(info)
                json.dump(cleaned_info, f, ensure_ascii=False, indent=2)

        # é¿å…è¯·æ±‚è¿‡å¿«
        time.sleep(2 if download_video else 1)

    return all_videos, all_channels, all_transcripts


def save_results(videos, channels, transcripts):
    """ä¿å­˜å¤„ç†ç»“æœä¸ºCSVå’ŒJSON"""

    # 1. ä¿å­˜è§†é¢‘ä¿¡æ¯ä¸ºCSV
    if videos:
        csv_path = os.path.join(OUTPUT_DIR, "videos_detailed.csv")
        with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=videos[0].keys())
            writer.writeheader()
            writer.writerows(videos)
        print(f"\nğŸ’¾ è§†é¢‘ä¿¡æ¯å·²ä¿å­˜: {csv_path}")

    # 2. ä¿å­˜é¢‘é“ä¿¡æ¯ä¸ºCSV
    if channels:
        csv_path = os.path.join(OUTPUT_DIR, "channels_detailed.csv")
        channel_list = list(channels.values())
        with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=channel_list[0].keys())
            writer.writeheader()
            writer.writerows(channel_list)
        print(f"ğŸ’¾ é¢‘é“ä¿¡æ¯å·²ä¿å­˜: {csv_path}")

    # 3. ä¿å­˜å­—å¹•ä¿¡æ¯ä¸ºJSONï¼ˆCSVä¸é€‚åˆå­˜å‚¨å±‚çº§æ•°æ®ï¼‰
    if transcripts:
        json_path = os.path.join(OUTPUT_DIR, "transcripts_all.json")
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(transcripts, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å­—å¹•ä¿¡æ¯å·²ä¿å­˜: {json_path}")

    # 4. è®¡ç®—è§†é¢‘æ–‡ä»¶æ€»å¤§å°
    total_size_mb = 0
    if DOWNLOAD_VIDEO and os.path.exists(VIDEOS_DIR):
        for root, dirs, files in os.walk(VIDEOS_DIR):
            for file in files:
                if file.endswith('.mp4'):
                    filepath = os.path.join(root, file)
                    total_size_mb += os.path.getsize(filepath) / (1024 * 1024)

    # 5. ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
    summary = {
        'timestamp': datetime.now().isoformat(),
        'total_videos': len(videos),
        'total_channels': len(channels),
        'videos_with_transcripts': len(transcripts),
        'downloaded_videos': DOWNLOAD_VIDEO,
        'video_quality': VIDEO_QUALITY if DOWNLOAD_VIDEO else 'N/A',
        'total_video_size_mb': round(total_size_mb, 2) if DOWNLOAD_VIDEO else 0,
        'statistics': {
            'videos_with_subtitles': sum(1 for v in videos if v['has_subtitles']),
            'videos_with_auto_captions': sum(1 for v in videos if v['has_automatic_captions']),
            'total_views': sum(v['view_count'] or 0 for v in videos),
            'total_likes': sum(v['like_count'] or 0 for v in videos),
            'total_duration_seconds': sum(v['duration'] or 0 for v in videos),
        }
    }

    summary_path = os.path.join(OUTPUT_DIR, "summary.json")
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ æ‘˜è¦æŠ¥å‘Šå·²ä¿å­˜: {summary_path}")

    if DOWNLOAD_VIDEO and total_size_mb > 0:
        print(f"\nğŸ“¦ è§†é¢‘æ–‡ä»¶æ€»å¤§å°: {total_size_mb:.2f} MB ({total_size_mb/1024:.2f} GB)")


def main():
    print("=" * 70)
    print("YouTube ä¸‹è½½æµ‹è¯• - ç¬¬äºŒæ­¥ï¼šä½¿ç”¨yt-dlpè·å–æ‰€æœ‰ç»´åº¦")
    print("=" * 70)
    print(f"\nâš™ï¸  é…ç½®:")
    print(f"   è¾“å…¥æ–‡ä»¶: {INPUT_CSV}")
    print(f"   è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print(f"   æµ‹è¯•æ•°é‡: å‰ {TEST_LIMIT} ä¸ªè§†é¢‘")
    print(f"   ä¸‹è½½è§†é¢‘: {'æ˜¯' if DOWNLOAD_VIDEO else 'å¦ï¼ˆä»…å…ƒæ•°æ®ï¼‰'}")
    if DOWNLOAD_VIDEO:
        print(f"   è§†é¢‘è´¨é‡: {VIDEO_QUALITY}")
        print(f"\n   âš ï¸  ä¸‹è½½10ä¸ªé«˜æ¸…è§†é¢‘é¢„è®¡éœ€è¦:")
        print(f"      - æ—¶é—´: 10-30åˆ†é’Ÿï¼ˆå–å†³äºç½‘é€Ÿå’Œè§†é¢‘é•¿åº¦ï¼‰")
        print(f"      - ç©ºé—´: 1-5 GBï¼ˆå–å†³äºè§†é¢‘è´¨é‡å’Œé•¿åº¦ï¼‰")

    # 1. è¯»å–video_idåˆ—è¡¨
    print("\nğŸ“– è¯»å–è§†é¢‘åˆ—è¡¨...")
    video_ids = read_video_ids_from_csv(INPUT_CSV, limit=TEST_LIMIT)

    if not video_ids:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°è§†é¢‘IDï¼Œç¨‹åºé€€å‡º")
        return

    print(f"âœ… è¯»å–åˆ° {len(video_ids)} ä¸ªè§†é¢‘ID")

    # 2. å¤„ç†è§†é¢‘
    videos, channels, transcripts = process_videos(video_ids, DOWNLOAD_VIDEO, VIDEO_QUALITY)

    # 3. ä¿å­˜ç»“æœ
    print("\n" + "=" * 70)
    print("ä¿å­˜ç»“æœ")
    print("=" * 70)
    save_results(videos, channels, transcripts)

    # 4. æ‰“å°ç»Ÿè®¡
    print("\n" + "=" * 70)
    print("âœ… æµ‹è¯•å®Œæˆ!")
    print("=" * 70)
    print(f"\nğŸ“Š ç»Ÿè®¡:")
    print(f"   æˆåŠŸå¤„ç†: {len(videos)}/{len(video_ids)} ä¸ªè§†é¢‘")
    print(f"   æ¶‰åŠé¢‘é“: {len(channels)} ä¸ª")
    print(f"   æœ‰å­—å¹•çš„: {len(transcripts)} ä¸ª")

    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"   - è§†é¢‘è¯¦æƒ…: {OUTPUT_DIR}/videos_detailed.csv")
    print(f"   - é¢‘é“è¯¦æƒ…: {OUTPUT_DIR}/channels_detailed.csv")
    print(f"   - å­—å¹•æ•°æ®: {OUTPUT_DIR}/transcripts_all.json")
    print(f"   - æ‘˜è¦æŠ¥å‘Š: {OUTPUT_DIR}/summary.json")
    print(f"   - å®Œæ•´JSON: {METADATA_DIR}/[video_id]_full.json")
    if DOWNLOAD_VIDEO:
        print(f"   - è§†é¢‘æ–‡ä»¶: {VIDEOS_DIR}/[video_id]/[video_id].mp4")
        print(f"   - å­—å¹•æ–‡ä»¶: {VIDEOS_DIR}/[video_id]/[video_id].en.json3")
    else:
        print(f"   - å­—å¹•æ–‡ä»¶: {TRANSCRIPTS_DIR}/[video_id]/*.json3")

    print("\nğŸ’¡ æç¤º:")
    print("   1. æ£€æŸ¥è¾“å‡ºæ–‡ä»¶ï¼Œç¡®è®¤æ•°æ®å®Œæ•´æ€§")
    print("   2. å¦‚æœæ»¡æ„ï¼Œå¯ä»¥ä¿®æ”¹ TEST_LIMIT å¤„ç†æ›´å¤šè§†é¢‘")
    if DOWNLOAD_VIDEO:
        print("   3. å¦‚æœåªéœ€è¦å…ƒæ•°æ®ï¼Œå¯ä»¥è®¾ç½® DOWNLOAD_VIDEO = False")
        print("   4. å¯ä»¥è°ƒæ•´ VIDEO_QUALITY ä¸º '720p' æˆ– '480p' èŠ‚çœç©ºé—´")
    else:
        print("   3. å¦‚æœéœ€è¦ä¸‹è½½è§†é¢‘ï¼Œå¯ä»¥è®¾ç½® DOWNLOAD_VIDEO = True")


if __name__ == "__main__":
    main()